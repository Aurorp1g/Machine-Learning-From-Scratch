===================================
模型评估
===================================


1. 泛化能力

建模的目的是是的模型不仅对已知数据，而且对未知数据都能有较好的预测能力。因此，基于损失函数的模型的训练误差和测试误差就自然是模型评估的标准。

损失函数：度量预测错误程度的函数
训练误差：训练数据集上的平均损失，虽然有意义，但本质不重要
测试误差：测试数据集上的平均损失，反应了模型对未知数据的预测能力

我们通常利用最小化训练误差来训练模型，但真正值得关心的是测试误差。通过观察测试误差可以帮助评估模型的泛化能力，即模型对未知数据的预测能力。

统计理论表明：如果训练集和测试集中的样本都是独立同分布产生的，则有 模型的训练误差的期望等于模型的测试误差的期望。


2. 过拟合与欠拟合

决定机器学习算法效果的两个因素：降低训练误差、缩小训练误差和测试误差的差距。这两个因素对应着机器学习中的两个主要挑战：欠拟合和过拟合。

过拟合：对已知数据预测的很好，但对未知数据预测很差
模型过于复杂
记住了噪音
训练样本过少

正则化
更多训练数据
early stopping

欠拟合：对已知数据预测的很差
模型过于简单


3. Bias-Variance
高偏差

高方差


偏差和方差衡量的是估计量的两个不同误差来源：

偏差衡量的是偏离真实值的误差的期望。
方差衡量的是由于数据采样的随机性可能导致的估计值的波动。
通常希望的是：

估计量的偏差比较小，即：估计量的期望值接近真实值。
估计量的方差比较小，即：估计量的波动比较小。

于是泛化误差可以分解为偏差、方差和噪声之和：

偏差  ：度量了学习算法的期望预测与真实结果之间的偏离程度，刻画了学习算法本身的拟合能力。
方差 ：度量了训练集的变动所导致的学习性能的变化，刻画了数据扰动造成的影响。
噪声  ：度量了在当前任务上任何学习算法所能达到的期望泛化误差的下界，刻画了学习问题本身的难度。

一般来说，偏差和方差是由冲突的，这称作偏差-方差窘境bias-variance dilemma。

给定学习任务：

在训练不足时模型的拟合能力不够强，训练数据的扰动不足以使模型产生显著变化，此时偏差主导了泛化误差。

随着训练程度的加深模型的拟合能力逐渐增强，训练数据发生的扰动逐渐被模型学习到，方差逐渐主导了泛化误差。

在训练充分后模型的拟合能力非常强，训练数据发生的轻微扰动都会导致模型发生显著变化。

若训练数据自身的、非全局的特性被模型学到了，则将发生过拟合。

=====
通常偏差方差反映了模型的过拟合与欠拟合。

高偏差对应于模型的欠拟合：模型过于简单，以至于未能很好的学习训练集，从而使得训练误差过高。

此时模型预测的方差较小，表示预测较稳定。但是模型预测的偏差会较大，表示预测不准确。

高方差对应于模型的过拟合：模型过于复杂，以至于将训练集的细节都学到，将训练集的一些细节当做普遍的规律，从而使得测试集误差与训练集误差相距甚远。

此时模型预测的偏差较小，表示预测较准确。但是模型预测的方差较大，表示预测较不稳定。

误差诊断：通过训练误差和测试误差来分析模型是否存在高方差、高偏差。

如果训练误差较高：说明模型的方差较大，模型出现了欠拟合。
如果训练误差较低，而训练误差较高：说明模型的偏差较大，出现了过拟合。
如果训练误差较低，测试误差也较低：说明模型的方差和偏差都适中，是一个比较理想的模型。
如果训练误差较高，且测试误差更高：说明模型的方差和偏差都较大。
上述分析的前提是：训练集、测试集的数据来自于同一个分布，


=====
高方差和高偏差是两种不同的情况。如果算法存在高偏差的问题，则准备更多训练数据其实没什么卵用。

所以首先要清楚：问题是高偏差还是高方差还是二者兼有。

如果模型存在高偏差，则通过以下策略可以缓解：

选择一个容量更大、更复杂的模型。
使用更先进的最优化算法。该策略通常在神经网络中使用。
如果模型存在高方差，则通过以下策略可以缓解：

增加更多的训练数据。它通过更多的训练样本来对模型参数增加约束，会降低模型容量。

如果有更多的训练数据，则一定会降低方差。

使用正则化。它通过正则化项来对模型参数增加约束，也会降低模型容量。

有时候更多的训练数据难以获取，只能使用正则化策略。

通常优先解决高偏差的问题。这是最低标准，要反复尝试，直到训练误差降低到足够小。

然后试图降低方差。

总之就是不断重复尝试，直到找到一个低偏差、低方差的模型。



4

3. 分类模型评价指标

7.1.1 准确率、错误率
测试准确率：测试数据集上的准确率（其中 为示性函数）：
准确率衡量的是有多少比例的样本被正确判别。

测试错误率：测试数据集上的错误率：
错误率衡量的是有多少比例的样本被判别错误，它也是损失函数为 0-1 损失时的测试误差。


查准率、查全率、混淆矩阵

对于二分类问题，通常将关注的类作为正类，其他类作为负类。令：
TP: TRUE POSITIVE 分类器将正类预测为正类的数量
FN: FALSE NEGATIVE 分类器将正类预测为负类的数量
FP: FALSE POSITIVE 分类器将负类预测为正类的数量
TN: TRUE NEGATIVE 分类器将负类预测为负类的数量

混淆矩阵
图

查准率（精确率）： Precision = TP/(TP+FP)，即所有被预测为正例的样本中，多少比例是真的正例？
查全率（召回率）： Recall = TP/(TP+FN)，即所有真的正例中，多少比例被模型预测出来了？

不同的问题中，有的侧重差准率，有的侧重差全率。

对于推荐系统，更侧重于查准率。即推荐的结果中，用户真正感兴趣的比例。因为给用户展示的窗口有限，必须尽可能的给用户展示他真实感兴趣的结果。
对于医学诊断系统，更侧重与查全率。即疾病被发现的比例。因为疾病如果被漏诊，则很可能导致病情恶化。
查准率和查全率是一对矛盾的度量。一般来说查准率高时查全率往往偏低，而查全率高时查准率往往偏低。

如果希望将所有的正例都找出来（查全率高），最简单的就是将所有的样本都视为正类，此时有FN=0。此时查准率就偏低（准确性降低）。
如果希望查准率高，则可以只挑选有把握的正例。最简单的就是挑选最有把握的那一个样本。此时有FP=0。此时查全率就偏低（只挑出了一个正例）。

F1 Score： F1 = 2TP/(2TP+FP+FN)，即精确率和召回率的调和平均。

P-R曲线

对二类分类问题，可以根据分类器的预测结果对样本进行排序：排在最前面的是分类器认为“最可能”是正类的样本，排在最后面的是分类器认为“最不可能”是正类的样本。

假设排序后的样本集合为 (x1,y1),(x2,y2)...,(xn,yn)预测为正类的概率依次为 (p1,p2,...pn), 在第 i 轮，将pi 作为分类阈值来。即：

。。image/pr曲线1

此时计算得到的查准率记做 Pi，查全率记做 Ri 。

以查准率为纵轴、查全率为横轴作图，就得到查准率-查全率曲线，简称 P-R曲线。该曲线由点 {(R1,P1),(R2,P2)...(Rn,Pn)} 组成。

P-R曲线从左上角(0,1) 到右下角(1,0) 。

开始时第一个样本（最可能为正例的）预测为正例，其它样本都预测为负类。此时：

查准率很高，几乎为1。 
查全率很低，几乎为0，大量的正例没有找到。
结束时所有的样本都预测为正类。此时：

查全率很高，正例全部找到了，查全率为1。
查准率很低，大量的负类被预测为正类。
P-R曲线直观显示出分类器在样本总体上的查全率、查准率。因此可以通过两个分类器在同一个测试集上的P-R 曲线来比较它们的预测能力：

如果分类器B的P-R曲线被分类器A的曲线完全包住，则可断言：A的性能好于B 。

如果分类器A的P-R曲线与分类器B的曲线发生了交叉，则难以一般性的断言两者的优劣，只能在具体的查准率和查全率下进行比较。

此时一个合理的判定依据是比较P-R曲线下面积大小，但这个值通常不容易计算。
可以考察平衡点。平衡点Break-Even Point:BEP是P-R曲线上查准率等于查全率的点，可以判定：平衡点较远的P-R曲线较好。

..image pr曲线3

2. ROC/AUC
定义真正例率(True Positive Rate) 为： TPR = TP/(TP+FN) 即召回率 。

它刻画了真正的正类中，被分类器找出来的比例。

定义假正例率(False Positive Rate) 为：FPR = FP/(TN+FP) 。

它刻画了模型将真实的负样本预测为正类的概率。它就等于 1 减去负类的查全率。

对二类分类问题，可以根据分类器的预测结果对样本进行排序：排在最前面的是分类器认为“最可能”是正类的样本，排在最后面的是分类器认为“最不可能”是正类的样本。

假设排序后的样本集合为 (x1,y1),(x2,y2)...,(xn,yn) ，预测为正类的概率依次为  (p1,p2,...pn) 。

在第 i 轮，将pi  作为分类阈值来。即
。。image/pr曲线1

此时计算得到的真正例率记做 TPRi，假正例率记做 FPRi。

以真正例率为纵轴、假正例率为横轴作图，就得到ROC曲线。该曲线由点 {(TPR1,FPR1),(TPR2,FPR2)...(TPRn,FPRn)} 组成。

。。image/ROC1

3. 对数损失
衡量预测概率分布与真实概率分布的查一下，越小越好，对预测概率敏感。


回归指标

1. 平均绝对误差 MAE（L1损失）

加权平均绝对误差，基于对每条样本考虑不同权重，比如时间。

2. 平均绝对百分误差

3. 均方根误差 RMSE

Goodness of Fit
1- sum of squared errors/total sums of squares