..
2. 最大似然估计

在机器学习中，我们经常使用模型描述从数据中观测结果的过程。例如，我们可能使用随机森林模型来分类客户是否会退订某项服务（称为客户翻转），也可能使用线性模型来基于广告开销预测利润（这将是线性回归的一个例子）。每个模型都包含各自的参数集合，参数集合最终定义了模型是什么样的。

我们可以用y = mx + c来表示线性模型。

最大似然估计是一个决定模型参数值的方法。参数值的选定最大化模型描述的过程的结果与数据实际观测所得的似然。

是利用已知的样本结果，反推最有可能（最大概率）导致这样结果的参数值的一种方法。

以上的定义可能仍然比较晦涩，所以让我们通过一个例子来理解这一概念。

假定我们从某一过程中观测到了10个数据点。例如，每个数据点可能表示一个学生回答一道考题的时长。

我们首先要决定，我们认为哪种模型是描述生成这些数据的最佳模型。这部分非常重要。至少，我们对使用哪种模型要有个概念。这通常源于某些专门的领域知识，不过我们这里不讨论这个。

对这些数据而言，我们假定数据生成过程可以通过高斯（正态）分布充分表达。从上图我们可以看到，10个点中的大部分都聚类在当中，少数点散布在左侧和右侧，因此，高斯分布看起来会是一个不错的选择。（仅仅只有10个数据点的情况下就做出这样的决定实在是欠考虑，不过既然其实是我生成了这些数据点，那我们姑且就这样吧。）

回忆一下，高斯分布有两个参数，均值μ和标注差σ。这些参数的不同值将造就不同的曲线（和前文的直线一样）。我们想知道哪条曲线最可能生成了我们观测到的数据点？（见下图）。最大似然估计是一个寻找拟合数据的最佳曲线的参数μ、σ的值的方法。
最大似然的目标是找到一些参数值，这些参数值对应的分布可以最大化观测到数据的概率。生成数据的真正分布是f1 ~ N(10, 2.25)，也就是上图中蓝色的曲线。

。。image

2.2 计算最大似然

这次我们假设有3个数据点，产生这3个数据点的过程可以通过高斯分布充分表达。这三个点分别是9、9.5、11。我们如何计算高斯分布的参数μ 、σ的最大似然估计呢？

我们想要计算的是观测到所有数据的全概率，即所有观测到的数据点的联合概率分布。为此我们需要计算一些条件概率，这可能会很困难。所以这里我们将做出我们的第一个假设。假设每个数据点的生成和其他点是独立的。这一假设让数学容易很多。如果事件（即生成数据的过程）是独立的，那么观测到所有数据的全概率是分别观测到每个数据点的概率的乘积（即边缘概率的乘积）。

观测到高斯分布生成的单个数据点x的（边缘）概率为：

P(x; μ, σ)中的分号强调之后的符号代表概率分布的参数，而不是条件概率（条件概率通常用竖线分割，例如P(A|B)）。

在我们的例子中，观测到3个数据点的全（联合）概率为：

。。图像

我们只需找出能最大化以上表达式的值的μ和σ的值。

如果你的数学课覆盖了微积分的话，你大概能意识到有一个帮助我们找到函数的最大（最小）值的技术。它叫做微分。我们只需找到函数的导数，将导数设为零，重新整理等式，将需要搜索的参数转变为等式的主题。看，我们得到了参数的MLE值。下面我将详细讲解这些步骤，不过我会假设读者知道常见函数如何求导。

2  对数似然
实际上，对上面的全概率表达式求导很麻烦。所以我们基本上总是通过取自然对数对其加以简化。由于自然对数是单调递增函数，所以这么做绝对没问题。单调递增函数意味着随着x轴的值增加，y轴的值也同样增加（见下图）。这很重要，因为这确保了当概率的对数达到最大值时，原概率函数同样达到最大值。因此我们可以操作简化了的对数似然，而不是原本的似然。


什么时候最小二乘法和最大似然估计是一样的？

最小二乘法是另一个估计机器学习模型的参数值的方法。当模型像上文的例子中一样呈高斯分布的时候，MLE估计等价于最小二乘法。关于两者在数学上的深层渊源，可以参考这些幻灯片。

直觉上，我们可以通过理解两者的目标来解释两个方法之间的联系。最小二乘法想要找到最小化数据点和回归线之间的距离平方和的直线（见下图）。最大似然估计想要最大化数据的全概率。如果数据符合高斯分布，那么当数据点接近均值时，我们找到了最大概率。由于高斯分布是对称的，因此这等价于最小化数据点和均值之间的距离。


3. 贝叶斯
https://mp.weixin.qq.com/s?__biz=MzI3ODkxODU3Mg==&mid=2247485317&idx=1&sn=ae0522b2128c46bbf06556e6990b2d94&chksm=eb4ee346dc396a50bccf99d6f211500c4b3229bf1a44ad3663fd3a960781dcba4e2547c01765&token=555639370&lang=zh_CN#rd

4. 边缘化 
https://mp.weixin.qq.com/s?__biz=MzI3ODkxODU3Mg==&mid=2247485685&idx=2&sn=28163bbe26da08b89026d306a55acdb4&chksm=eb4eec36dc396520c3f5cb3b5a9ba82934463c0c7ab1c3213c53d003fb0c0db0616c5c82e826&token=555639370&lang=zh_CN#rd


6. 常见分布
https://medium.com/@srowen/common-probability-distributions-347e6b945ce4


7 概率论中的独立同分布?

独立：就是每次抽样之间是没有关系的,不会相互影响。就像我抛色子每次抛到几就是几这就是独立的。但若我要两次抛的和大于8,其余的不算,那么第一次抛和第二次抛就不独立了,因为第二次抛的时候结果是和第一次相关的。不懂可查看独立性。

同分布：就是每次抽样,样本都服从同样的一个分布抛色子每次得到任意点数的概率都是1/6,这就是同分布的但若我第一次抛一个六面的色子,第二次抛一个正12面体的色子,就不再是同分布了

独立同分布：就是每次抽样之间独立而且同分布的意思

追问：同分布是指服从同一分布函数么？答：是的。


概率处理(TODO)
log转换
延迟归一化（Delayed Normalization）
Jenson不等式
CSDN 博文 https://blog.csdn.net/u012566895/article/details/51220127?utm_source=blogxgwz0